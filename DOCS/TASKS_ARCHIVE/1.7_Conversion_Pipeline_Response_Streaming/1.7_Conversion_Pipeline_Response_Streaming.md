# Task PRD: 1.7 â€” Conversion Pipeline & Response Streaming

**Version:** 1.0.0  
**Source:** Workplan.md Task 1.7  
**Priority:** Critical  
**Phase:** 1  
**Effort:** 5-6 hours  
**Dependencies:** Task 1.6  

## Objective

Implement conversion pipeline with ZIP extraction, Swift CLI invocation, Markdown collection, and streaming response using StreamingResponse or FileResponse to avoid loading entire ZIP in RAM.

## Current State Analysis

Based on repository inspection:
- FastAPI application structure is complete from Task 1.3
- File upload and validation are implemented from Task 1.4
- Workspace management is implemented from Task 1.5
- SubprocessManager for Swift CLI is implemented from Task 1.6
- Current endpoint returns JSON response with mock conversion
- Need to implement full conversion pipeline and streaming response

## Implementation Plan

### Subtask 1.7.1: Implement Complete Conversion Pipeline
**Files to touch:**
- `app/api/v1/endpoints.py` (enhance conversion pipeline)
- `app/services/conversion_pipeline.py` (create conversion service)

**Acceptance Criteria:**
- [x] ZIP files are extracted to workspace before conversion
- [x] Swift CLI is invoked on extracted archive
- [x] Generated Markdown files are collected and organized
- [x] Pipeline handles both single and multiple output files
- [x] Conversion progress is logged appropriately

### Subtask 1.7.2: Implement Streaming Response
**Files to touch:**
- `app/api/v1/endpoints.py` (add streaming response)
- `app/services/response_streaming.py` (create streaming service)

**Acceptance Criteria:**
- [x] Response uses StreamingResponse or FileResponse
- [x] Output ZIP is created on-the-fly (not buffered in RAM)
- [x] Appropriate headers are set (Content-Type, Content-Disposition)
- [x] Large conversions don't cause memory issues
- [x] Response streaming is logged

### Subtask 1.7.3: Handle Conversion Errors Gracefully
**Files to touch:**
- `app/api/v1/endpoints.py` (enhance error handling)
- `app/services/conversion_pipeline.py` (add error handling)

**Acceptance Criteria:**
- [x] Conversion errors return 500 with CLI stderr in response body
- [x] Workspace cleanup happens even on conversion errors
- [x] Partial conversion results are handled appropriately
- [x] Error responses include detailed debugging information
- [x] Error scenarios are logged comprehensively

### Subtask 1.7.4: Optimize Performance and Memory Usage
**Files to touch:**
- `app/services/response_streaming.py` (optimize streaming)
- `app/services/conversion_pipeline.py` (optimize pipeline)

**Acceptance Criteria:**
- [x] Large ZIP files don't cause memory exhaustion
- [x] Streaming starts quickly without waiting for full conversion
- [x] Temporary files are cleaned up promptly
- [x] Memory usage is monitored and logged
- [x] Performance meets NFR requirements

## Definition of Done

### Functional Requirements
- [x] Complete conversion pipeline from ZIP to Markdown
- [x] Streaming response avoids memory issues
- [x] Output ZIP contains all generated Markdown files
- [x] Error responses include CLI stderr details

### Technical Requirements
- [x] Response is streamed (not buffered entirely in RAM)
- [x] Cleanup occurs on both success and failure
- [x] Memory usage is optimized for large files
- [x] Code follows FastAPI best practices

### API Integration
```
POST /api/v1/convert
Process:
1. Validate and store uploaded file in workspace
2. Extract ZIP file to workspace/extracted/
3. Run Swift CLI: docc2context input.zip output.md
4. Collect generated Markdown files
5. Create output ZIP on-the-fly
6. Stream ZIP response to client
7. Cleanup workspace (always executed)
```

### Response Format
```
Success:
- Content-Type: application/zip
- Content-Disposition: attachment; filename="converted.zip"
- Body: Streamed ZIP file with Markdown content

Error:
- Status: 500
- Content-Type: application/json
- Body: {"detail": "Conversion failed: <CLI stderr>"}
```

### Verification Commands
```bash
# Test streaming response with real file
curl -X POST -F "file=@large_doccarchive.zip" \
  http://localhost:8000/api/v1/convert \
  --output converted.zip

# Test error handling
curl -X POST -F "file=@invalid.zip" \
  http://localhost:8000/api/v1/convert

# Test memory usage with large file
python -c "
import requests
import time
with open('large_file.zip', 'rb') as f:
    response = requests.post('http://localhost:8000/api/v1/convert', files={'file': f}, stream=True)
    for chunk in response.iter_content(chunk_size=8192):
        pass  # Process streaming response
"
```

### Integration Points
- **Task 1.6**: SubprocessManager provides CLI execution
- **Task 1.5**: WorkspaceManager provides isolated environment
- **Task 1.4**: File validation ensures safe input
- **Task 2.1**: Frontend will consume streaming response

## Security Considerations

- **Path validation**: Ensure all file operations stay within workspace
- **ZIP bomb protection**: Already implemented in file validation
- **Resource limits**: Streaming prevents memory exhaustion
- **Output sanitization**: Validate generated Markdown content

## Risk Mitigation

- **Memory issues**: Streaming response prevents buffering large files
- **Conversion failures**: Detailed error reporting for debugging
- **Partial outputs**: Handle incomplete conversions gracefully
- **Cleanup failures**: Ensure workspace cleanup even on errors

---

**Archived:** 2026-01-10
